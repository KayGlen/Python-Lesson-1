# -*- coding: utf-8 -*-
"""Classification_Session1_AI_for_CT_2021-22.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ncgxs2deFSjC-DrvvuK4rJK02_7_Xzi4

# Session 1 - Plan for classification task & dataset collation

If you're going to be using Google's Colaboratory for training your deep learning models.  I suggest you go there (https://colab.research.google.com/) and create a new notebook.  Notebooks can be saved in Google Drive or GitHub and also downloaded to be run locally.

This week 1's task is to come up with an idea for a creative classification task and start putting together a dataset.  The creative task that I've set myself is to recognise different species of jellyfish.  I aim to do this by training a classification network on images of a few different species of jellyfish.  A potential application of this tool is an underwater monitoring system that tells swimmers/surfers whether any jellyfish in the waters are poisonous.

# Dataset collation

This week I've started collating my dataset.  I've so far found images for four different species (i.e. Lion's Mane Jellyfish, Moon Jellyfish, Pacific Sea Nettles and White Spotted Jellyfish). 

To automate this task I used a Google Chrome Web Extension called [Image Downloader Continued](https://chrome.google.com/webstore/detail/image-downloader-continue/jfkjbfhcfaoldhgbnkekkoheganchiea?hl=en) and Google Image Search to download images for each species into sub folders.  I then went through each subfolder and removed any images which didn't contain the object of interest, were too small (e.g. thumbnails 100x100 pixels) or contained text/watermarks.

# Dataset split

I then divided each my datasets into three sets for training, validation and testing. A common split is 70-15-15. So training (70%), validation (15%) and testing (15%). Pay attention to the folder structure. Inside my dataset folder I have three folders (train, val and test) and then inside each of these are the four folders one for each class. I used Python and the [split-folders library](https://pypi.org/project/split-folders/) to help with this process.

# Loading the dataset in Colab

I've uploaded my dataset to Google Drive in a zipped folder and to start with I need to connect this Colab to my Google Drive.
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""If you look in the Files tab on the left you can now see a `gdrive` folder. I can then go the folder that I want and copy the file path.  Now I can unzip the file. """

!unzip '/content/gdrive/MyDrive/Jellyfish_Final_Test.zip' > /dev/null

"""You should now be able to see a folder with your dataset in (you might need to press the refresh folder icon just below where 'Files' is written).  Next let's display one of the images to check that they work!"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

image = mpimg.imread('/content/images (48).jpg')
plt.imshow(image)
plt.show()